Model: "functional_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 64)        1792      
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 16, 16, 64)        0         
_________________________________________________________________
dropout (Dropout)            (None, 16, 16, 64)        0         
_________________________________________________________________
batch_normalization (BatchNo (None, 16, 16, 64)        256       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 8, 8, 128)         73856     
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 128)         0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 128)         0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 8, 8, 128)         512       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 4, 4, 128)         147584    
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 128)         0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 128)         0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 4, 4, 128)         512       
_________________________________________________________________
flatten (Flatten)            (None, 2048)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               524544    
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2570      
=================================================================
Total params: 752,650
Trainable params: 751,498
Non-trainable params: 1,152
_________________________________________________________________
None
1563/1563 [==============================] - 37s 24ms/step - loss: 1.9858 - accuracy: 0.3287 - val_loss: 1.5734 - val_accuracy: 0.4527
1563/1563 [==============================] - 36s 23ms/step - loss: 1.3893 - accuracy: 0.5017 - val_loss: 1.3264 - val_accuracy: 0.5307
1563/1563 [==============================] - 36s 23ms/step - loss: 1.2901 - accuracy: 0.5396 - val_loss: 1.1917 - val_accuracy: 0.5735
1563/1563 [==============================] - 36s 23ms/step - loss: 1.2121 - accuracy: 0.5662 - val_loss: 1.0922 - val_accuracy: 0.6102
1563/1563 [==============================] - 36s 23ms/step - loss: 1.1483 - accuracy: 0.5950 - val_loss: 1.2450 - val_accuracy: 0.5563
1563/1563 [==============================] - 37s 24ms/step - loss: 1.1005 - accuracy: 0.6079 - val_loss: 1.2942 - val_accuracy: 0.5569
1563/1563 [==============================] - 36s 23ms/step - loss: 1.0524 - accuracy: 0.6265 - val_loss: 1.2815 - val_accuracy: 0.5572
1563/1563 [==============================] - 35s 22ms/step - loss: 1.0214 - accuracy: 0.6424 - val_loss: 1.0004 - val_accuracy: 0.6463
1563/1563 [==============================] - 35s 22ms/step - loss: 0.9948 - accuracy: 0.6501 - val_loss: 1.1177 - val_accuracy: 0.6107
1563/1563 [==============================] - 35s 22ms/step - loss: 0.9735 - accuracy: 0.6547 - val_loss: 0.9368 - val_accuracy: 0.6696
1563/1563 [==============================] - 34s 22ms/step - loss: 0.9424 - accuracy: 0.6665 - val_loss: 0.9418 - val_accuracy: 0.6649
1563/1563 [==============================] - 33s 21ms/step - loss: 0.9294 - accuracy: 0.6737 - val_loss: 0.8912 - val_accuracy: 0.6823
1563/1563 [==============================] - 33s 21ms/step - loss: 0.9030 - accuracy: 0.6832 - val_loss: 0.8566 - val_accuracy: 0.6986
1563/1563 [==============================] - 33s 21ms/step - loss: 0.8915 - accuracy: 0.6857 - val_loss: 0.8385 - val_accuracy: 0.7098
1563/1563 [==============================] - 33s 21ms/step - loss: 0.8817 - accuracy: 0.6869 - val_loss: 0.8936 - val_accuracy: 0.6904
1563/1563 [==============================] - 46s 30ms/step - loss: 0.8680 - accuracy: 0.6940 - val_loss: 0.8997 - val_accuracy: 0.6802
1563/1563 [==============================] - 36s 23ms/step - loss: 0.8574 - accuracy: 0.6979 - val_loss: 0.8610 - val_accuracy: 0.6942
1563/1563 [==============================] - 36s 23ms/step - loss: 0.8370 - accuracy: 0.7040 - val_loss: 0.8960 - val_accuracy: 0.6897
1563/1563 [==============================] - 36s 23ms/step - loss: 0.8309 - accuracy: 0.7058 - val_loss: 0.8211 - val_accuracy: 0.7119
1563/1563 [==============================] - 36s 23ms/step - loss: 0.8270 - accuracy: 0.7106 - val_loss: 0.8526 - val_accuracy: 0.6963
1563/1563 [==============================] - 37s 23ms/step - loss: 0.8114 - accuracy: 0.7150 - val_loss: 0.8013 - val_accuracy: 0.7205
1563/1563 [==============================] - 36s 23ms/step - loss: 0.8044 - accuracy: 0.7141 - val_loss: 0.8143 - val_accuracy: 0.7186
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7945 - accuracy: 0.7191 - val_loss: 0.8456 - val_accuracy: 0.7086
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7890 - accuracy: 0.7198 - val_loss: 0.8099 - val_accuracy: 0.7244
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7780 - accuracy: 0.7225 - val_loss: 0.8063 - val_accuracy: 0.7222
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7777 - accuracy: 0.7252 - val_loss: 0.8779 - val_accuracy: 0.7010
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7663 - accuracy: 0.7270 - val_loss: 0.9197 - val_accuracy: 0.6792
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7608 - accuracy: 0.7305 - val_loss: 0.8947 - val_accuracy: 0.6903
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7519 - accuracy: 0.7339 - val_loss: 0.7653 - val_accuracy: 0.7354
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7437 - accuracy: 0.7363 - val_loss: 0.7963 - val_accuracy: 0.7230
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7318 - accuracy: 0.7411 - val_loss: 0.7700 - val_accuracy: 0.7315
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7277 - accuracy: 0.7423 - val_loss: 0.7839 - val_accuracy: 0.7317
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7252 - accuracy: 0.7435 - val_loss: 0.8049 - val_accuracy: 0.7216
1563/1563 [==============================] - 37s 23ms/step - loss: 0.7214 - accuracy: 0.7436 - val_loss: 0.7948 - val_accuracy: 0.7266
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7205 - accuracy: 0.7457 - val_loss: 0.7991 - val_accuracy: 0.7251
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7062 - accuracy: 0.7509 - val_loss: 0.8734 - val_accuracy: 0.6970
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7129 - accuracy: 0.7474 - val_loss: 0.7823 - val_accuracy: 0.7315
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7034 - accuracy: 0.7502 - val_loss: 0.7868 - val_accuracy: 0.7279
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6917 - accuracy: 0.7547 - val_loss: 0.7852 - val_accuracy: 0.7284
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6992 - accuracy: 0.7522 - val_loss: 1.3101 - val_accuracy: 0.6089
1563/1563 [==============================] - 36s 23ms/step - loss: 0.7013 - accuracy: 0.7519 - val_loss: 0.8770 - val_accuracy: 0.7065
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6859 - accuracy: 0.7576 - val_loss: 0.8160 - val_accuracy: 0.7204
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6866 - accuracy: 0.7561 - val_loss: 0.7526 - val_accuracy: 0.7426
1563/1563 [==============================] - 37s 23ms/step - loss: 0.6822 - accuracy: 0.7595 - val_loss: 0.7888 - val_accuracy: 0.7262
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6878 - accuracy: 0.7563 - val_loss: 0.7978 - val_accuracy: 0.7256
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6725 - accuracy: 0.7613 - val_loss: 1.0199 - val_accuracy: 0.6742
1563/1563 [==============================] - 37s 23ms/step - loss: 0.6735 - accuracy: 0.7628 - val_loss: 0.7513 - val_accuracy: 0.7429
1563/1563 [==============================] - 37s 23ms/step - loss: 0.6691 - accuracy: 0.7629 - val_loss: 0.7795 - val_accuracy: 0.7340
1563/1563 [==============================] - 37s 23ms/step - loss: 0.6702 - accuracy: 0.7630 - val_loss: 0.7854 - val_accuracy: 0.7331
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6684 - accuracy: 0.7634 - val_loss: 1.0555 - val_accuracy: 0.6460
1563/1563 [==============================] - 49s 31ms/step - loss: 0.6615 - accuracy: 0.7625 - val_loss: 0.7497 - val_accuracy: 0.7414
1563/1563 [==============================] - 37s 24ms/step - loss: 0.6662 - accuracy: 0.7624 - val_loss: 0.7252 - val_accuracy: 0.7498
1563/1563 [==============================] - 40s 26ms/step - loss: 0.6515 - accuracy: 0.7682 - val_loss: 0.7486 - val_accuracy: 0.7398
1563/1563 [==============================] - 40s 25ms/step - loss: 0.6513 - accuracy: 0.7700 - val_loss: 0.7834 - val_accuracy: 0.7337
1563/1563 [==============================] - 47s 30ms/step - loss: 0.6442 - accuracy: 0.7714 - val_loss: 0.7613 - val_accuracy: 0.7378
1563/1563 [==============================] - 44s 28ms/step - loss: 0.6375 - accuracy: 0.7751 - val_loss: 0.8345 - val_accuracy: 0.7197
1563/1563 [==============================] - 39s 25ms/step - loss: 0.6392 - accuracy: 0.7734 - val_loss: 0.7523 - val_accuracy: 0.7410
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6349 - accuracy: 0.7751 - val_loss: 0.7667 - val_accuracy: 0.7406
1563/1563 [==============================] - 36s 23ms/step - loss: 0.6336 - accuracy: 0.7745 - val_loss: 0.7452 - val_accuracy: 0.7392
1563/1563 [==============================] - 37s 23ms/step - loss: 0.6373 - accuracy: 0.7739 - val_loss: 0.7386 - val_accuracy: 0.7449
1563/1563 [==============================] - 38s 24ms/step - loss: 0.6350 - accuracy: 0.7724 - val_loss: 0.7420 - val_accuracy: 0.7457
1563/1563 [==============================] - 35s 22ms/step - loss: 0.6209 - accuracy: 0.7805 - val_loss: 0.7421 - val_accuracy: 0.7457
1563/1563 [==============================] - 34s 22ms/step - loss: 0.6191 - accuracy: 0.7806 - val_loss: 0.7538 - val_accuracy: 0.7399
1563/1563 [==============================] - 34s 22ms/step - loss: 0.6157 - accuracy: 0.7816 - val_loss: 0.7378 - val_accuracy: 0.7448
1563/1563 [==============================] - 33s 21ms/step - loss: 0.6196 - accuracy: 0.7807 - val_loss: 0.7306 - val_accuracy: 0.7480
1563/1563 [==============================] - 34s 22ms/step - loss: 0.6245 - accuracy: 0.7776 - val_loss: 0.7757 - val_accuracy: 0.7336
