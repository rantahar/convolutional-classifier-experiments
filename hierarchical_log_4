['classifier.py', 'hierarchical', '4']
hierarchical
Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 16, 16, 4)    112         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 16, 16, 4)    112         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 16, 16, 4)    112         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 16, 16, 4)    112         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 16, 16, 4)    112         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 16, 16, 4)    112         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 16, 16, 4)    112         input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 16, 16, 4)    112         input_1[0][0]                    
__________________________________________________________________________________________________
leaky_re_lu (LeakyReLU)         (None, 16, 16, 4)    0           conv2d[0][0]                     
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 16, 16, 4)    0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 16, 16, 4)    0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_3 (LeakyReLU)       (None, 16, 16, 4)    0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 4)    0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_5 (LeakyReLU)       (None, 16, 16, 4)    0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 4)    0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_7 (LeakyReLU)       (None, 16, 16, 4)    0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
dropout (Dropout)               (None, 16, 16, 4)    0           leaky_re_lu[0][0]                
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 16, 16, 4)    0           leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 16, 16, 4)    0           leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 16, 16, 4)    0           leaky_re_lu_3[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 16, 16, 4)    0           leaky_re_lu_4[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 16, 16, 4)    0           leaky_re_lu_5[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 16, 16, 4)    0           leaky_re_lu_6[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 16, 16, 4)    0           leaky_re_lu_7[0][0]              
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 16, 16, 4)    16          dropout[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 16, 16, 4)    16          dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 16, 16, 4)    16          dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 16, 16, 4)    16          dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 16, 16, 4)    16          dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 16, 16, 4)    16          dropout_5[0][0]                  
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 16, 16, 4)    16          dropout_6[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 16, 16, 4)    16          dropout_7[0][0]                  
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 16, 16, 8)    0           batch_normalization[0][0]        
                                                                 batch_normalization_1[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 16, 16, 8)    0           batch_normalization_2[0][0]      
                                                                 batch_normalization_3[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 16, 16, 8)    0           batch_normalization_4[0][0]      
                                                                 batch_normalization_5[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 16, 16, 8)    0           batch_normalization_6[0][0]      
                                                                 batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 8, 8, 16)     1168        concatenate[0][0]                
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 8, 8, 16)     1168        concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 8, 8, 16)     1168        concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 8, 8, 16)     1168        concatenate_3[0][0]              
__________________________________________________________________________________________________
leaky_re_lu_8 (LeakyReLU)       (None, 8, 8, 16)     0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_9 (LeakyReLU)       (None, 8, 8, 16)     0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
leaky_re_lu_10 (LeakyReLU)      (None, 8, 8, 16)     0           conv2d_10[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_11 (LeakyReLU)      (None, 8, 8, 16)     0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 8, 8, 16)     0           leaky_re_lu_8[0][0]              
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 8, 8, 16)     0           leaky_re_lu_9[0][0]              
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 8, 8, 16)     0           leaky_re_lu_10[0][0]             
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 8, 8, 16)     0           leaky_re_lu_11[0][0]             
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 8, 8, 16)     64          dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 8, 8, 16)     64          dropout_9[0][0]                  
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 8, 8, 16)     64          dropout_10[0][0]                 
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 8, 8, 16)     64          dropout_11[0][0]                 
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 8, 8, 32)     0           batch_normalization_8[0][0]      
                                                                 batch_normalization_9[0][0]      
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 8, 8, 32)     0           batch_normalization_10[0][0]     
                                                                 batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 4, 4, 32)     9248        concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 4, 4, 32)     9248        concatenate_5[0][0]              
__________________________________________________________________________________________________
leaky_re_lu_12 (LeakyReLU)      (None, 4, 4, 32)     0           conv2d_12[0][0]                  
__________________________________________________________________________________________________
leaky_re_lu_13 (LeakyReLU)      (None, 4, 4, 32)     0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 4, 4, 32)     0           leaky_re_lu_12[0][0]             
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 4, 4, 32)     0           leaky_re_lu_13[0][0]             
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 4, 4, 32)     128         dropout_12[0][0]                 
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 4, 4, 32)     128         dropout_13[0][0]                 
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 4, 4, 64)     0           batch_normalization_12[0][0]     
                                                                 batch_normalization_13[0][0]     
__________________________________________________________________________________________________
flatten (Flatten)               (None, 1024)         0           concatenate_6[0][0]              
__________________________________________________________________________________________________
dense (Dense)                   (None, 256)          262400      flatten[0][0]                    
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 256)          0           dense[0][0]                      
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 256)          1024        dropout_14[0][0]                 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           2570        batch_normalization_14[0][0]     
==================================================================================================
Total params: 290,698
Trainable params: 289,866
Non-trainable params: 832
__________________________________________________________________________________________________
Epoch 1/100
1563/1563 [==============================] - 26s 17ms/step - loss: 2.0440 - accuracy: 0.3133 - val_loss: 1.4369 - val_accuracy: 0.4751
Epoch 2/100
1563/1563 [==============================] - 26s 17ms/step - loss: 1.4920 - accuracy: 0.4629 - val_loss: 1.2467 - val_accuracy: 0.5516
Epoch 3/100
1563/1563 [==============================] - 26s 17ms/step - loss: 1.3607 - accuracy: 0.5142 - val_loss: 1.3715 - val_accuracy: 0.5222
Epoch 4/100
1563/1563 [==============================] - 26s 17ms/step - loss: 1.3075 - accuracy: 0.5332 - val_loss: 1.1241 - val_accuracy: 0.5931
Epoch 5/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.2447 - accuracy: 0.5574 - val_loss: 1.1215 - val_accuracy: 0.5953
Epoch 6/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.2063 - accuracy: 0.5710 - val_loss: 1.1315 - val_accuracy: 0.5967
Epoch 7/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.1663 - accuracy: 0.5864 - val_loss: 1.1236 - val_accuracy: 0.6096
Epoch 8/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.1571 - accuracy: 0.5874 - val_loss: 1.0421 - val_accuracy: 0.6332
Epoch 9/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.1315 - accuracy: 0.5997 - val_loss: 1.0453 - val_accuracy: 0.6292
Epoch 10/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.1227 - accuracy: 0.6021 - val_loss: 1.0477 - val_accuracy: 0.6286
Epoch 11/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.0908 - accuracy: 0.6131 - val_loss: 0.9453 - val_accuracy: 0.6700
Epoch 12/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.0719 - accuracy: 0.6190 - val_loss: 0.9621 - val_accuracy: 0.6661
Epoch 13/100
1563/1563 [==============================] - 29s 19ms/step - loss: 1.0652 - accuracy: 0.6242 - val_loss: 1.0968 - val_accuracy: 0.6023
Epoch 14/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.0492 - accuracy: 0.6314 - val_loss: 0.9267 - val_accuracy: 0.6745
Epoch 15/100
1563/1563 [==============================] - 27s 17ms/step - loss: 1.0380 - accuracy: 0.6354 - val_loss: 0.9372 - val_accuracy: 0.6756
Epoch 16/100
1563/1563 [==============================] - 30s 19ms/step - loss: 1.0238 - accuracy: 0.6392 - val_loss: 1.0824 - val_accuracy: 0.6198
Epoch 17/100
1563/1563 [==============================] - 26s 16ms/step - loss: 1.0119 - accuracy: 0.6407 - val_loss: 0.9786 - val_accuracy: 0.6622
Epoch 18/100
1563/1563 [==============================] - 28s 18ms/step - loss: 1.0130 - accuracy: 0.6408 - val_loss: 0.8962 - val_accuracy: 0.6838
Epoch 19/100
1563/1563 [==============================] - 30s 19ms/step - loss: 1.0043 - accuracy: 0.6425 - val_loss: 0.8991 - val_accuracy: 0.6766
Epoch 20/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.9915 - accuracy: 0.6484 - val_loss: 0.9174 - val_accuracy: 0.6771
Epoch 21/100
1563/1563 [==============================] - 29s 18ms/step - loss: 0.9881 - accuracy: 0.6498 - val_loss: 0.9020 - val_accuracy: 0.6880
Epoch 22/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9821 - accuracy: 0.6528 - val_loss: 0.8675 - val_accuracy: 0.6918
Epoch 23/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.9885 - accuracy: 0.6508 - val_loss: 0.8735 - val_accuracy: 0.6972
Epoch 24/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9754 - accuracy: 0.6548 - val_loss: 0.9347 - val_accuracy: 0.6682
Epoch 25/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9676 - accuracy: 0.6567 - val_loss: 0.9669 - val_accuracy: 0.6527
Epoch 26/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9584 - accuracy: 0.6608 - val_loss: 0.8669 - val_accuracy: 0.6919
Epoch 27/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.9552 - accuracy: 0.6638 - val_loss: 0.8589 - val_accuracy: 0.6959
Epoch 28/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9515 - accuracy: 0.6612 - val_loss: 0.9422 - val_accuracy: 0.6655
Epoch 29/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9608 - accuracy: 0.6617 - val_loss: 0.9316 - val_accuracy: 0.6706
Epoch 30/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9514 - accuracy: 0.6649 - val_loss: 0.8581 - val_accuracy: 0.6985
Epoch 31/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9411 - accuracy: 0.6666 - val_loss: 0.8998 - val_accuracy: 0.6852
Epoch 32/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9482 - accuracy: 0.6652 - val_loss: 0.8462 - val_accuracy: 0.7027
Epoch 33/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.9403 - accuracy: 0.6691 - val_loss: 0.9250 - val_accuracy: 0.6796
Epoch 34/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.9327 - accuracy: 0.6691 - val_loss: 0.9366 - val_accuracy: 0.6669
Epoch 35/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.9307 - accuracy: 0.6755 - val_loss: 0.8778 - val_accuracy: 0.6928
Epoch 36/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.9244 - accuracy: 0.6708 - val_loss: 0.8602 - val_accuracy: 0.7005
Epoch 37/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.9144 - accuracy: 0.6756 - val_loss: 0.8616 - val_accuracy: 0.7001
Epoch 38/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9160 - accuracy: 0.6745 - val_loss: 0.8195 - val_accuracy: 0.7130
Epoch 39/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9160 - accuracy: 0.6775 - val_loss: 0.8280 - val_accuracy: 0.7069
Epoch 40/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9116 - accuracy: 0.6802 - val_loss: 0.9185 - val_accuracy: 0.6729
Epoch 41/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.9140 - accuracy: 0.6763 - val_loss: 1.0003 - val_accuracy: 0.6486
Epoch 42/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.9137 - accuracy: 0.6795 - val_loss: 0.8829 - val_accuracy: 0.6871
Epoch 43/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.9141 - accuracy: 0.6762 - val_loss: 0.8296 - val_accuracy: 0.7100
Epoch 44/100
1563/1563 [==============================] - 31s 20ms/step - loss: 0.8964 - accuracy: 0.6815 - val_loss: 0.8611 - val_accuracy: 0.6958
Epoch 45/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.8973 - accuracy: 0.6807 - val_loss: 0.9866 - val_accuracy: 0.6535
Epoch 46/100
1563/1563 [==============================] - 32s 20ms/step - loss: 0.8928 - accuracy: 0.6855 - val_loss: 0.7968 - val_accuracy: 0.7212
Epoch 47/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.9025 - accuracy: 0.6817 - val_loss: 0.8465 - val_accuracy: 0.7031
Epoch 48/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8820 - accuracy: 0.6893 - val_loss: 0.8877 - val_accuracy: 0.6847
Epoch 49/100
1563/1563 [==============================] - 27s 18ms/step - loss: 0.9083 - accuracy: 0.6815 - val_loss: 0.8000 - val_accuracy: 0.7161
Epoch 50/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8965 - accuracy: 0.6852 - val_loss: 1.0252 - val_accuracy: 0.6440
Epoch 51/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8810 - accuracy: 0.6885 - val_loss: 0.8337 - val_accuracy: 0.6999
Epoch 52/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.8841 - accuracy: 0.6879 - val_loss: 0.8995 - val_accuracy: 0.6848
Epoch 53/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.8855 - accuracy: 0.6854 - val_loss: 0.8405 - val_accuracy: 0.7026
Epoch 54/100
1563/1563 [==============================] - 29s 18ms/step - loss: 0.8869 - accuracy: 0.6904 - val_loss: 0.8457 - val_accuracy: 0.6995
Epoch 55/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8801 - accuracy: 0.6900 - val_loss: 0.7841 - val_accuracy: 0.7269
Epoch 56/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.8767 - accuracy: 0.6918 - val_loss: 0.8256 - val_accuracy: 0.7062
Epoch 57/100
1563/1563 [==============================] - 32s 20ms/step - loss: 0.8693 - accuracy: 0.6901 - val_loss: 0.8081 - val_accuracy: 0.7138
Epoch 58/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.8711 - accuracy: 0.6920 - val_loss: 0.8218 - val_accuracy: 0.7100
Epoch 59/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8655 - accuracy: 0.6950 - val_loss: 0.8313 - val_accuracy: 0.7134
Epoch 60/100
1563/1563 [==============================] - 27s 18ms/step - loss: 0.8643 - accuracy: 0.6938 - val_loss: 0.9264 - val_accuracy: 0.6720
Epoch 61/100
1563/1563 [==============================] - 27s 18ms/step - loss: 0.8782 - accuracy: 0.6900 - val_loss: 0.7867 - val_accuracy: 0.7252
Epoch 62/100
1563/1563 [==============================] - 27s 18ms/step - loss: 0.8599 - accuracy: 0.6949 - val_loss: 0.7929 - val_accuracy: 0.7241
Epoch 63/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8603 - accuracy: 0.6967 - val_loss: 0.8259 - val_accuracy: 0.7118
Epoch 64/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8599 - accuracy: 0.6953 - val_loss: 0.7955 - val_accuracy: 0.7217
Epoch 65/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8613 - accuracy: 0.6956 - val_loss: 0.8004 - val_accuracy: 0.7201
Epoch 66/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8620 - accuracy: 0.6967 - val_loss: 0.7638 - val_accuracy: 0.7318
Epoch 67/100
1563/1563 [==============================] - 29s 18ms/step - loss: 0.8586 - accuracy: 0.6976 - val_loss: 0.8027 - val_accuracy: 0.7130
Epoch 68/100
1563/1563 [==============================] - 29s 18ms/step - loss: 0.8486 - accuracy: 0.6976 - val_loss: 0.8013 - val_accuracy: 0.7230
Epoch 69/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8535 - accuracy: 0.6963 - val_loss: 0.7836 - val_accuracy: 0.7236
Epoch 70/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8505 - accuracy: 0.6999 - val_loss: 0.7648 - val_accuracy: 0.7326
Epoch 71/100
1563/1563 [==============================] - 29s 18ms/step - loss: 0.8568 - accuracy: 0.6992 - val_loss: 0.7835 - val_accuracy: 0.7280
Epoch 72/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.8551 - accuracy: 0.6999 - val_loss: 0.7968 - val_accuracy: 0.7252
Epoch 73/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8499 - accuracy: 0.7014 - val_loss: 0.7958 - val_accuracy: 0.7222
Epoch 74/100
1563/1563 [==============================] - 29s 18ms/step - loss: 0.8468 - accuracy: 0.7023 - val_loss: 0.8691 - val_accuracy: 0.6923
Epoch 75/100
1563/1563 [==============================] - 29s 18ms/step - loss: 0.8422 - accuracy: 0.7031 - val_loss: 0.7756 - val_accuracy: 0.7266
Epoch 76/100
1563/1563 [==============================] - 29s 18ms/step - loss: 0.8512 - accuracy: 0.6968 - val_loss: 0.7740 - val_accuracy: 0.7240
Epoch 77/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.8452 - accuracy: 0.7025 - val_loss: 0.7731 - val_accuracy: 0.7260
Epoch 78/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8325 - accuracy: 0.7073 - val_loss: 0.8094 - val_accuracy: 0.7166
Epoch 79/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8458 - accuracy: 0.6999 - val_loss: 0.8186 - val_accuracy: 0.7109
Epoch 80/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8398 - accuracy: 0.7054 - val_loss: 0.7956 - val_accuracy: 0.7227
Epoch 81/100
1563/1563 [==============================] - 27s 18ms/step - loss: 0.8370 - accuracy: 0.7044 - val_loss: 0.8084 - val_accuracy: 0.7128
Epoch 82/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8260 - accuracy: 0.7051 - val_loss: 0.7786 - val_accuracy: 0.7263
Epoch 83/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8394 - accuracy: 0.7029 - val_loss: 0.7722 - val_accuracy: 0.7336
Epoch 84/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.8308 - accuracy: 0.7066 - val_loss: 0.7755 - val_accuracy: 0.7308
Epoch 85/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8354 - accuracy: 0.7049 - val_loss: 0.7551 - val_accuracy: 0.7336
Epoch 86/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8417 - accuracy: 0.7006 - val_loss: 0.7733 - val_accuracy: 0.7297
Epoch 87/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8299 - accuracy: 0.7109 - val_loss: 0.7846 - val_accuracy: 0.7267
Epoch 88/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8267 - accuracy: 0.7090 - val_loss: 0.8923 - val_accuracy: 0.6846
Epoch 89/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.8353 - accuracy: 0.7075 - val_loss: 0.7826 - val_accuracy: 0.7271
Epoch 90/100
1563/1563 [==============================] - 30s 19ms/step - loss: 0.8159 - accuracy: 0.7147 - val_loss: 0.8356 - val_accuracy: 0.7061
Epoch 91/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8281 - accuracy: 0.7068 - val_loss: 0.8221 - val_accuracy: 0.7110
Epoch 92/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8287 - accuracy: 0.7071 - val_loss: 0.8193 - val_accuracy: 0.7154
Epoch 93/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8190 - accuracy: 0.7112 - val_loss: 0.8035 - val_accuracy: 0.7230
Epoch 94/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.8223 - accuracy: 0.7116 - val_loss: 0.7840 - val_accuracy: 0.7252
Epoch 95/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8279 - accuracy: 0.7088 - val_loss: 0.8371 - val_accuracy: 0.7043
Epoch 96/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8207 - accuracy: 0.7107 - val_loss: 0.7501 - val_accuracy: 0.7385
Epoch 97/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8222 - accuracy: 0.7066 - val_loss: 0.7742 - val_accuracy: 0.7275
Epoch 98/100
1563/1563 [==============================] - 29s 19ms/step - loss: 0.8187 - accuracy: 0.7107 - val_loss: 0.8095 - val_accuracy: 0.7165
Epoch 99/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8231 - accuracy: 0.7117 - val_loss: 0.7608 - val_accuracy: 0.7339
Epoch 100/100
1563/1563 [==============================] - 28s 18ms/step - loss: 0.8203 - accuracy: 0.7093 - val_loss: 0.8172 - val_accuracy: 0.7123
