['classifier.py', 'std', '16', 'focus']
std
std
Model: "functional_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            
__________________________________________________________________________________________________
conv2d (Conv2D)                 (None, 16, 16, 16)   448         input_1[0][0]                    
__________________________________________________________________________________________________
leaky_re_lu (LeakyReLU)         (None, 16, 16, 16)   0           conv2d[0][0]                     
__________________________________________________________________________________________________
dropout (Dropout)               (None, 16, 16, 16)   0           leaky_re_lu[0][0]                
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 16, 16, 16)   64          dropout[0][0]                    
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 8, 8, 32)     4640        batch_normalization[0][0]        
__________________________________________________________________________________________________
leaky_re_lu_1 (LeakyReLU)       (None, 8, 8, 32)     0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 8, 8, 32)     0           leaky_re_lu_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 8, 8, 32)     128         dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 4, 4, 32)     9248        batch_normalization_1[0][0]      
__________________________________________________________________________________________________
leaky_re_lu_2 (LeakyReLU)       (None, 4, 4, 32)     0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 4, 4, 32)     0           leaky_re_lu_2[0][0]              
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 4, 4, 32)     128         dropout_2[0][0]                  
__________________________________________________________________________________________________
dense (Dense)                   (None, 4, 4, 4)      132         batch_normalization_2[0][0]      
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 16, 4)        0           dense[0][0]                      
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 4, 4, 32)     1056        batch_normalization_2[0][0]      
__________________________________________________________________________________________________
softmax (Softmax)               (None, 16, 4)        0           reshape_1[0][0]                  
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 16, 32)       0           dense_1[0][0]                    
__________________________________________________________________________________________________
dot (Dot)                       (None, 4, 32)        0           softmax[0][0]                    
                                                                 reshape_2[0][0]                  
__________________________________________________________________________________________________
reshape_3 (Reshape)             (None, 128)          0           dot[0][0]                        
__________________________________________________________________________________________________
flatten (Flatten)               (None, 128)          0           reshape_3[0][0]                  
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 256)          33024       flatten[0][0]                    
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 256)          0           dense_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 256)          1024        dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 10)           2570        batch_normalization_4[0][0]      
==================================================================================================
Total params: 52,462
Trainable params: 51,790
Non-trainable params: 672
__________________________________________________________________________________________________
Epoch 1/100
1563/1563 [==============================] - 15s 9ms/step - loss: 2.1697 - accuracy: 0.2279 - val_loss: 1.7050 - val_accuracy: 0.3736
Epoch 2/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.7550 - accuracy: 0.3508 - val_loss: 1.5634 - val_accuracy: 0.4224
Epoch 3/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.6724 - accuracy: 0.3808 - val_loss: 1.6219 - val_accuracy: 0.4215
Epoch 4/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.6155 - accuracy: 0.4045 - val_loss: 1.4859 - val_accuracy: 0.4515
Epoch 5/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.5838 - accuracy: 0.4207 - val_loss: 1.5006 - val_accuracy: 0.4467
Epoch 6/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.5555 - accuracy: 0.4313 - val_loss: 1.5581 - val_accuracy: 0.4418
Epoch 7/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.5370 - accuracy: 0.4420 - val_loss: 1.4811 - val_accuracy: 0.4705
Epoch 8/100
1563/1563 [==============================] - 13s 9ms/step - loss: 1.5046 - accuracy: 0.4493 - val_loss: 1.4153 - val_accuracy: 0.4933
Epoch 9/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.4946 - accuracy: 0.4562 - val_loss: 1.3673 - val_accuracy: 0.4996
Epoch 10/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.4701 - accuracy: 0.4648 - val_loss: 1.5669 - val_accuracy: 0.4507
Epoch 11/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.4589 - accuracy: 0.4744 - val_loss: 1.3258 - val_accuracy: 0.5239
Epoch 12/100
1563/1563 [==============================] - 13s 9ms/step - loss: 1.4513 - accuracy: 0.4747 - val_loss: 1.3869 - val_accuracy: 0.4880
Epoch 13/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.4322 - accuracy: 0.4824 - val_loss: 1.6697 - val_accuracy: 0.4245
Epoch 14/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.4346 - accuracy: 0.4829 - val_loss: 1.3583 - val_accuracy: 0.5076
Epoch 15/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.4257 - accuracy: 0.4839 - val_loss: 1.4238 - val_accuracy: 0.4865
Epoch 16/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.4251 - accuracy: 0.4847 - val_loss: 1.3746 - val_accuracy: 0.5053
Epoch 17/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.4096 - accuracy: 0.4887 - val_loss: 1.5063 - val_accuracy: 0.4825
Epoch 18/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.4138 - accuracy: 0.4886 - val_loss: 1.2341 - val_accuracy: 0.5499
Epoch 19/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.3942 - accuracy: 0.4969 - val_loss: 1.2534 - val_accuracy: 0.5491
Epoch 20/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.3932 - accuracy: 0.4972 - val_loss: 1.2339 - val_accuracy: 0.5496
Epoch 21/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.3847 - accuracy: 0.4977 - val_loss: 1.2793 - val_accuracy: 0.5302
Epoch 22/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.3868 - accuracy: 0.4994 - val_loss: 1.2116 - val_accuracy: 0.5633
Epoch 23/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3734 - accuracy: 0.5052 - val_loss: 1.2678 - val_accuracy: 0.5344
Epoch 24/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3615 - accuracy: 0.5106 - val_loss: 1.2011 - val_accuracy: 0.5640
Epoch 25/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3567 - accuracy: 0.5131 - val_loss: 1.2469 - val_accuracy: 0.5580
Epoch 26/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3709 - accuracy: 0.5047 - val_loss: 1.2515 - val_accuracy: 0.5474
Epoch 27/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3528 - accuracy: 0.5164 - val_loss: 1.2397 - val_accuracy: 0.5505
Epoch 28/100
1563/1563 [==============================] - 13s 9ms/step - loss: 1.3486 - accuracy: 0.5139 - val_loss: 1.1883 - val_accuracy: 0.5679
Epoch 29/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3413 - accuracy: 0.5158 - val_loss: 1.1680 - val_accuracy: 0.5787
Epoch 30/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3446 - accuracy: 0.5152 - val_loss: 1.1630 - val_accuracy: 0.5802
Epoch 31/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3390 - accuracy: 0.5171 - val_loss: 1.2224 - val_accuracy: 0.5542
Epoch 32/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3359 - accuracy: 0.5166 - val_loss: 1.2776 - val_accuracy: 0.5381
Epoch 33/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3364 - accuracy: 0.5168 - val_loss: 1.3358 - val_accuracy: 0.5140
Epoch 34/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3288 - accuracy: 0.5210 - val_loss: 1.2519 - val_accuracy: 0.5415
Epoch 35/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3355 - accuracy: 0.5146 - val_loss: 1.2027 - val_accuracy: 0.5636
Epoch 36/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.3324 - accuracy: 0.5225 - val_loss: 1.1852 - val_accuracy: 0.5679
Epoch 37/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3391 - accuracy: 0.5220 - val_loss: 1.3394 - val_accuracy: 0.5147
Epoch 38/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3148 - accuracy: 0.5266 - val_loss: 1.5855 - val_accuracy: 0.4390
Epoch 39/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3173 - accuracy: 0.5257 - val_loss: 1.1730 - val_accuracy: 0.5723
Epoch 40/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3140 - accuracy: 0.5256 - val_loss: 1.1405 - val_accuracy: 0.5883
Epoch 41/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3139 - accuracy: 0.5251 - val_loss: 1.1532 - val_accuracy: 0.5813
Epoch 42/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3105 - accuracy: 0.5268 - val_loss: 1.1275 - val_accuracy: 0.5919
Epoch 43/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3178 - accuracy: 0.5246 - val_loss: 1.1247 - val_accuracy: 0.5939
Epoch 44/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3096 - accuracy: 0.5285 - val_loss: 1.1408 - val_accuracy: 0.5946
Epoch 45/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3104 - accuracy: 0.5293 - val_loss: 1.2095 - val_accuracy: 0.5663
Epoch 46/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3069 - accuracy: 0.5302 - val_loss: 1.1829 - val_accuracy: 0.5774
Epoch 47/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3100 - accuracy: 0.5307 - val_loss: 1.2618 - val_accuracy: 0.5444
Epoch 48/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3185 - accuracy: 0.5259 - val_loss: 1.1580 - val_accuracy: 0.5835
Epoch 49/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3038 - accuracy: 0.5337 - val_loss: 1.1739 - val_accuracy: 0.5800
Epoch 50/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3074 - accuracy: 0.5295 - val_loss: 1.1246 - val_accuracy: 0.5952
Epoch 51/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3030 - accuracy: 0.5328 - val_loss: 1.1914 - val_accuracy: 0.5708
Epoch 52/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3057 - accuracy: 0.5340 - val_loss: 1.1880 - val_accuracy: 0.5686
Epoch 53/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3086 - accuracy: 0.5302 - val_loss: 1.1652 - val_accuracy: 0.5767
Epoch 54/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3038 - accuracy: 0.5314 - val_loss: 1.2940 - val_accuracy: 0.5319
Epoch 55/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.2983 - accuracy: 0.5320 - val_loss: 1.5342 - val_accuracy: 0.4811
Epoch 56/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3143 - accuracy: 0.5275 - val_loss: 1.1828 - val_accuracy: 0.5785
Epoch 57/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3089 - accuracy: 0.5304 - val_loss: 1.3623 - val_accuracy: 0.5256
Epoch 58/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3075 - accuracy: 0.5311 - val_loss: 1.2058 - val_accuracy: 0.5787
Epoch 59/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3026 - accuracy: 0.5332 - val_loss: 1.1577 - val_accuracy: 0.5868
Epoch 60/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.2925 - accuracy: 0.5368 - val_loss: 1.1875 - val_accuracy: 0.5680
Epoch 61/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2838 - accuracy: 0.5402 - val_loss: 1.1537 - val_accuracy: 0.5885
Epoch 62/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.2861 - accuracy: 0.5416 - val_loss: 1.1184 - val_accuracy: 0.5952
Epoch 63/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2968 - accuracy: 0.5376 - val_loss: 1.1196 - val_accuracy: 0.6008
Epoch 64/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2973 - accuracy: 0.5385 - val_loss: 1.1937 - val_accuracy: 0.5684
Epoch 65/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2930 - accuracy: 0.5356 - val_loss: 1.1613 - val_accuracy: 0.5863
Epoch 66/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2843 - accuracy: 0.5374 - val_loss: 1.2452 - val_accuracy: 0.5545
Epoch 67/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.2904 - accuracy: 0.5369 - val_loss: 1.2149 - val_accuracy: 0.5635
Epoch 68/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.2913 - accuracy: 0.5382 - val_loss: 1.0984 - val_accuracy: 0.6110
Epoch 69/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2920 - accuracy: 0.5371 - val_loss: 1.1584 - val_accuracy: 0.5830
Epoch 70/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2956 - accuracy: 0.5337 - val_loss: 1.1317 - val_accuracy: 0.5957
Epoch 71/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2799 - accuracy: 0.5388 - val_loss: 1.0924 - val_accuracy: 0.6117
Epoch 72/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2837 - accuracy: 0.5407 - val_loss: 1.3173 - val_accuracy: 0.5279
Epoch 73/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.2831 - accuracy: 0.5436 - val_loss: 1.1472 - val_accuracy: 0.5949
Epoch 74/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.2931 - accuracy: 0.5352 - val_loss: 1.1307 - val_accuracy: 0.6001
Epoch 75/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.2913 - accuracy: 0.5401 - val_loss: 1.0920 - val_accuracy: 0.6124
Epoch 76/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2767 - accuracy: 0.5451 - val_loss: 1.0930 - val_accuracy: 0.6121
Epoch 77/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2779 - accuracy: 0.5438 - val_loss: 1.3153 - val_accuracy: 0.5237
Epoch 78/100
1563/1563 [==============================] - 13s 9ms/step - loss: 1.2860 - accuracy: 0.5378 - val_loss: 1.1062 - val_accuracy: 0.6013
Epoch 79/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2808 - accuracy: 0.5403 - val_loss: 1.1156 - val_accuracy: 0.6024
Epoch 80/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2672 - accuracy: 0.5461 - val_loss: 1.0650 - val_accuracy: 0.6177
Epoch 81/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.2689 - accuracy: 0.5474 - val_loss: 1.2725 - val_accuracy: 0.5391
Epoch 82/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.2774 - accuracy: 0.5438 - val_loss: 1.0987 - val_accuracy: 0.6079
Epoch 83/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2664 - accuracy: 0.5453 - val_loss: 1.1031 - val_accuracy: 0.6094
Epoch 84/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2702 - accuracy: 0.5458 - val_loss: 1.1486 - val_accuracy: 0.5782
Epoch 85/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2768 - accuracy: 0.5417 - val_loss: 1.2137 - val_accuracy: 0.5634
Epoch 86/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2782 - accuracy: 0.5431 - val_loss: 1.1212 - val_accuracy: 0.5940
Epoch 87/100
1563/1563 [==============================] - 11s 7ms/step - loss: 1.2691 - accuracy: 0.5454 - val_loss: 1.1380 - val_accuracy: 0.5912
Epoch 88/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2684 - accuracy: 0.5464 - val_loss: 1.2804 - val_accuracy: 0.5473
Epoch 89/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2783 - accuracy: 0.5437 - val_loss: 1.1301 - val_accuracy: 0.5918
Epoch 90/100
1563/1563 [==============================] - 12s 7ms/step - loss: 1.2738 - accuracy: 0.5444 - val_loss: 1.1814 - val_accuracy: 0.5771
Epoch 91/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2777 - accuracy: 0.5437 - val_loss: 1.1178 - val_accuracy: 0.5950
Epoch 92/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.2631 - accuracy: 0.5469 - val_loss: 1.0719 - val_accuracy: 0.6152
Epoch 93/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2691 - accuracy: 0.5417 - val_loss: 1.1515 - val_accuracy: 0.5829
Epoch 94/100
1563/1563 [==============================] - 13s 9ms/step - loss: 1.2693 - accuracy: 0.5462 - val_loss: 1.1398 - val_accuracy: 0.5901
Epoch 95/100
1563/1563 [==============================] - 13s 9ms/step - loss: 1.2636 - accuracy: 0.5479 - val_loss: 1.2329 - val_accuracy: 0.5568
Epoch 96/100
1563/1563 [==============================] - 14s 9ms/step - loss: 1.2617 - accuracy: 0.5469 - val_loss: 1.1206 - val_accuracy: 0.6005
Epoch 97/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.2678 - accuracy: 0.5455 - val_loss: 1.0932 - val_accuracy: 0.6095
Epoch 98/100
1563/1563 [==============================] - 13s 8ms/step - loss: 1.2712 - accuracy: 0.5411 - val_loss: 1.0492 - val_accuracy: 0.6285
Epoch 99/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2692 - accuracy: 0.5456 - val_loss: 1.0797 - val_accuracy: 0.6163
Epoch 100/100
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2718 - accuracy: 0.5448 - val_loss: 1.1238 - val_accuracy: 0.5998
