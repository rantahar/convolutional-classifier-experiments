Model: "functional_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 16)        448       
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 16, 16, 16)        0         
_________________________________________________________________
dropout (Dropout)            (None, 16, 16, 16)        0         
_________________________________________________________________
batch_normalization (BatchNo (None, 16, 16, 16)        64        
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 8, 8, 32)          4640      
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 32)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 32)          0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 8, 8, 32)          128       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 4, 4, 32)          9248      
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 32)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 32)          0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 4, 4, 32)          128       
_________________________________________________________________
flatten (Flatten)            (None, 512)               0         
_________________________________________________________________
dense (Dense)                (None, 256)               131328    
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2570      
=================================================================
Total params: 149,578
Trainable params: 148,906
Non-trainable params: 672
_________________________________________________________________
None
1563/1563 [==============================] - 13s 8ms/step - loss: 2.0620 - accuracy: 0.3019 - val_loss: 1.5729 - val_accuracy: 0.4378
1563/1563 [==============================] - 13s 8ms/step - loss: 1.5173 - accuracy: 0.4505 - val_loss: 1.3589 - val_accuracy: 0.5105
1563/1563 [==============================] - 13s 8ms/step - loss: 1.4293 - accuracy: 0.4886 - val_loss: 1.3203 - val_accuracy: 0.5361
1563/1563 [==============================] - 13s 8ms/step - loss: 1.3710 - accuracy: 0.5094 - val_loss: 1.2145 - val_accuracy: 0.5680
1563/1563 [==============================] - 14s 9ms/step - loss: 1.3368 - accuracy: 0.5220 - val_loss: 1.1542 - val_accuracy: 0.5945
1563/1563 [==============================] - 12s 8ms/step - loss: 1.3045 - accuracy: 0.5324 - val_loss: 1.2117 - val_accuracy: 0.5737
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2795 - accuracy: 0.5443 - val_loss: 1.1574 - val_accuracy: 0.5910
1563/1563 [==============================] - 13s 8ms/step - loss: 1.2639 - accuracy: 0.5495 - val_loss: 1.1669 - val_accuracy: 0.5836
1563/1563 [==============================] - 12s 8ms/step - loss: 1.2414 - accuracy: 0.5597 - val_loss: 1.1287 - val_accuracy: 0.5983
1563/1563 [==============================] - 13s 8ms/step - loss: 1.2292 - accuracy: 0.5633 - val_loss: 1.1030 - val_accuracy: 0.6164
1563/1563 [==============================] - 13s 8ms/step - loss: 1.2154 - accuracy: 0.5679 - val_loss: 1.2683 - val_accuracy: 0.5589
1563/1563 [==============================] - 13s 8ms/step - loss: 1.2074 - accuracy: 0.5729 - val_loss: 1.0285 - val_accuracy: 0.6335
1563/1563 [==============================] - 12s 8ms/step - loss: 1.1912 - accuracy: 0.5780 - val_loss: 1.1052 - val_accuracy: 0.6117
1563/1563 [==============================] - 12s 8ms/step - loss: 1.1908 - accuracy: 0.5754 - val_loss: 1.0979 - val_accuracy: 0.6051
1563/1563 [==============================] - 12s 8ms/step - loss: 1.1777 - accuracy: 0.5814 - val_loss: 1.0224 - val_accuracy: 0.6397
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1640 - accuracy: 0.5875 - val_loss: 0.9931 - val_accuracy: 0.6491
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1648 - accuracy: 0.5874 - val_loss: 0.9817 - val_accuracy: 0.6560
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1586 - accuracy: 0.5912 - val_loss: 1.3009 - val_accuracy: 0.5482
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1475 - accuracy: 0.5929 - val_loss: 1.1085 - val_accuracy: 0.6098
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1435 - accuracy: 0.5944 - val_loss: 1.0202 - val_accuracy: 0.6395
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1412 - accuracy: 0.5958 - val_loss: 0.9866 - val_accuracy: 0.6537
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1373 - accuracy: 0.5990 - val_loss: 1.0042 - val_accuracy: 0.6454
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1243 - accuracy: 0.6007 - val_loss: 1.0269 - val_accuracy: 0.6380
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1223 - accuracy: 0.6023 - val_loss: 0.9606 - val_accuracy: 0.6596
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1217 - accuracy: 0.6039 - val_loss: 0.9974 - val_accuracy: 0.6439
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1155 - accuracy: 0.6044 - val_loss: 0.9553 - val_accuracy: 0.6643
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1108 - accuracy: 0.6071 - val_loss: 1.0989 - val_accuracy: 0.6040
1563/1563 [==============================] - 11s 7ms/step - loss: 1.1089 - accuracy: 0.6078 - val_loss: 1.0385 - val_accuracy: 0.6332
1563/1563 [==============================] - 13s 8ms/step - loss: 1.1056 - accuracy: 0.6087 - val_loss: 1.0037 - val_accuracy: 0.6480
1563/1563 [==============================] - 12s 7ms/step - loss: 1.1034 - accuracy: 0.6102 - val_loss: 0.9936 - val_accuracy: 0.6532
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0956 - accuracy: 0.6101 - val_loss: 0.9353 - val_accuracy: 0.6684
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0995 - accuracy: 0.6131 - val_loss: 0.9517 - val_accuracy: 0.6606
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0873 - accuracy: 0.6158 - val_loss: 0.9541 - val_accuracy: 0.6619
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0898 - accuracy: 0.6157 - val_loss: 0.9967 - val_accuracy: 0.6409
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0893 - accuracy: 0.6137 - val_loss: 1.0868 - val_accuracy: 0.6185
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0919 - accuracy: 0.6133 - val_loss: 0.9614 - val_accuracy: 0.6655
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0856 - accuracy: 0.6174 - val_loss: 0.9652 - val_accuracy: 0.6539
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0823 - accuracy: 0.6179 - val_loss: 1.0089 - val_accuracy: 0.6393
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0741 - accuracy: 0.6227 - val_loss: 0.9417 - val_accuracy: 0.6711
1563/1563 [==============================] - 14s 9ms/step - loss: 1.0747 - accuracy: 0.6183 - val_loss: 0.9672 - val_accuracy: 0.6657
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0737 - accuracy: 0.6222 - val_loss: 0.9203 - val_accuracy: 0.6734
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0728 - accuracy: 0.6199 - val_loss: 0.9037 - val_accuracy: 0.6824
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0739 - accuracy: 0.6205 - val_loss: 0.9481 - val_accuracy: 0.6661
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0682 - accuracy: 0.6214 - val_loss: 0.9192 - val_accuracy: 0.6801
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0716 - accuracy: 0.6206 - val_loss: 0.9201 - val_accuracy: 0.6766
1563/1563 [==============================] - 14s 9ms/step - loss: 1.0588 - accuracy: 0.6262 - val_loss: 0.9641 - val_accuracy: 0.6647
1563/1563 [==============================] - 15s 9ms/step - loss: 1.0654 - accuracy: 0.6219 - val_loss: 0.8976 - val_accuracy: 0.6869
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0627 - accuracy: 0.6250 - val_loss: 0.9472 - val_accuracy: 0.6680
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0570 - accuracy: 0.6264 - val_loss: 1.0244 - val_accuracy: 0.6337
1563/1563 [==============================] - 13s 9ms/step - loss: 1.0572 - accuracy: 0.6252 - val_loss: 0.8938 - val_accuracy: 0.6878
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0600 - accuracy: 0.6257 - val_loss: 0.9337 - val_accuracy: 0.6767
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0520 - accuracy: 0.6295 - val_loss: 1.0663 - val_accuracy: 0.6318
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0524 - accuracy: 0.6279 - val_loss: 0.8969 - val_accuracy: 0.6944
1563/1563 [==============================] - 14s 9ms/step - loss: 1.0503 - accuracy: 0.6306 - val_loss: 0.9293 - val_accuracy: 0.6715
1563/1563 [==============================] - 13s 9ms/step - loss: 1.0490 - accuracy: 0.6310 - val_loss: 1.0699 - val_accuracy: 0.6262
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0530 - accuracy: 0.6284 - val_loss: 0.9896 - val_accuracy: 0.6583
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0505 - accuracy: 0.6275 - val_loss: 0.9028 - val_accuracy: 0.6897
1563/1563 [==============================] - 12s 8ms/step - loss: 1.0495 - accuracy: 0.6308 - val_loss: 0.9053 - val_accuracy: 0.6868
1563/1563 [==============================] - 13s 9ms/step - loss: 1.0423 - accuracy: 0.6332 - val_loss: 0.9500 - val_accuracy: 0.6632
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0483 - accuracy: 0.6321 - val_loss: 0.8887 - val_accuracy: 0.6926
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0429 - accuracy: 0.6319 - val_loss: 0.8993 - val_accuracy: 0.6862
1563/1563 [==============================] - 12s 7ms/step - loss: 1.0480 - accuracy: 0.6288 - val_loss: 0.9983 - val_accuracy: 0.6460
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0450 - accuracy: 0.6316 - val_loss: 0.8918 - val_accuracy: 0.6884
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0443 - accuracy: 0.6315 - val_loss: 0.9529 - val_accuracy: 0.6641
1563/1563 [==============================] - 11s 7ms/step - loss: 1.0414 - accuracy: 0.6329 - val_loss: 1.1251 - val_accuracy: 0.6036
1563/1563 [==============================] - 13s 8ms/step - loss: 1.0412 - accuracy: 0.6291 - val_loss: 0.8762 - val_accuracy: 0.6936
