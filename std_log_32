Model: "functional_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 16, 16, 32)        896       
_________________________________________________________________
leaky_re_lu (LeakyReLU)      (None, 16, 16, 32)        0         
_________________________________________________________________
dropout (Dropout)            (None, 16, 16, 32)        0         
_________________________________________________________________
batch_normalization (BatchNo (None, 16, 16, 32)        128       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 8, 8, 64)          18496     
_________________________________________________________________
leaky_re_lu_1 (LeakyReLU)    (None, 8, 8, 64)          0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 8, 64)          0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 8, 8, 64)          256       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     
_________________________________________________________________
leaky_re_lu_2 (LeakyReLU)    (None, 4, 4, 64)          0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 4, 64)          0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 4, 4, 64)          256       
_________________________________________________________________
flatten (Flatten)            (None, 1024)              0         
_________________________________________________________________
dense (Dense)                (None, 256)               262400    
_________________________________________________________________
dropout_3 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 256)               1024      
_________________________________________________________________
dense_1 (Dense)              (None, 10)                2570      
=================================================================
Total params: 322,954
Trainable params: 322,122
Non-trainable params: 832
_________________________________________________________________
None
1563/1563 [==============================] - 18s 12ms/step - loss: 2.0120 - accuracy: 0.3146 - val_loss: 1.4938 - val_accuracy: 0.4620
1563/1563 [==============================] - 17s 11ms/step - loss: 1.4516 - accuracy: 0.4750 - val_loss: 1.2876 - val_accuracy: 0.5405
1563/1563 [==============================] - 17s 11ms/step - loss: 1.3612 - accuracy: 0.5116 - val_loss: 1.2474 - val_accuracy: 0.5554
1563/1563 [==============================] - 17s 11ms/step - loss: 1.3006 - accuracy: 0.5354 - val_loss: 1.3816 - val_accuracy: 0.5182
1563/1563 [==============================] - 17s 11ms/step - loss: 1.2435 - accuracy: 0.5569 - val_loss: 1.1738 - val_accuracy: 0.5726
1563/1563 [==============================] - 18s 11ms/step - loss: 1.2050 - accuracy: 0.5726 - val_loss: 1.0557 - val_accuracy: 0.6214
1563/1563 [==============================] - 18s 11ms/step - loss: 1.1696 - accuracy: 0.5822 - val_loss: 1.0290 - val_accuracy: 0.6384
1563/1563 [==============================] - 18s 11ms/step - loss: 1.1374 - accuracy: 0.5964 - val_loss: 1.2217 - val_accuracy: 0.5754
1563/1563 [==============================] - 17s 11ms/step - loss: 1.1161 - accuracy: 0.6048 - val_loss: 0.9822 - val_accuracy: 0.6531
1563/1563 [==============================] - 17s 11ms/step - loss: 1.0926 - accuracy: 0.6110 - val_loss: 1.1838 - val_accuracy: 0.5799
1563/1563 [==============================] - 18s 11ms/step - loss: 1.0787 - accuracy: 0.6165 - val_loss: 0.9535 - val_accuracy: 0.6615
1563/1563 [==============================] - 18s 11ms/step - loss: 1.0610 - accuracy: 0.6250 - val_loss: 0.9482 - val_accuracy: 0.6619
1563/1563 [==============================] - 18s 11ms/step - loss: 1.0462 - accuracy: 0.6316 - val_loss: 0.9373 - val_accuracy: 0.6669
1563/1563 [==============================] - 17s 11ms/step - loss: 1.0318 - accuracy: 0.6389 - val_loss: 0.9771 - val_accuracy: 0.6515
1563/1563 [==============================] - 18s 11ms/step - loss: 1.0207 - accuracy: 0.6388 - val_loss: 1.0344 - val_accuracy: 0.6327
1563/1563 [==============================] - 18s 11ms/step - loss: 1.0145 - accuracy: 0.6439 - val_loss: 0.9312 - val_accuracy: 0.6745
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9953 - accuracy: 0.6501 - val_loss: 0.9149 - val_accuracy: 0.6759
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9895 - accuracy: 0.6501 - val_loss: 0.9484 - val_accuracy: 0.6611
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9802 - accuracy: 0.6531 - val_loss: 0.9817 - val_accuracy: 0.6576
1563/1563 [==============================] - 17s 11ms/step - loss: 0.9666 - accuracy: 0.6596 - val_loss: 1.0031 - val_accuracy: 0.6427
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9579 - accuracy: 0.6614 - val_loss: 0.9529 - val_accuracy: 0.6695
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9549 - accuracy: 0.6638 - val_loss: 0.8729 - val_accuracy: 0.6922
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9496 - accuracy: 0.6669 - val_loss: 0.8457 - val_accuracy: 0.7027
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9388 - accuracy: 0.6679 - val_loss: 0.8363 - val_accuracy: 0.7095
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9366 - accuracy: 0.6667 - val_loss: 0.8605 - val_accuracy: 0.6993
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9283 - accuracy: 0.6701 - val_loss: 0.8925 - val_accuracy: 0.6881
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9262 - accuracy: 0.6723 - val_loss: 0.8251 - val_accuracy: 0.7129
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9144 - accuracy: 0.6771 - val_loss: 0.8900 - val_accuracy: 0.6877
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9057 - accuracy: 0.6820 - val_loss: 0.8265 - val_accuracy: 0.7121
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9070 - accuracy: 0.6802 - val_loss: 0.8869 - val_accuracy: 0.6841
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9101 - accuracy: 0.6811 - val_loss: 0.9071 - val_accuracy: 0.6783
1563/1563 [==============================] - 18s 11ms/step - loss: 0.9005 - accuracy: 0.6814 - val_loss: 0.8141 - val_accuracy: 0.7181
1563/1563 [==============================] - 18s 11ms/step - loss: 0.8943 - accuracy: 0.6826 - val_loss: 0.8087 - val_accuracy: 0.7177
1563/1563 [==============================] - 18s 11ms/step - loss: 0.8842 - accuracy: 0.6877 - val_loss: 0.7884 - val_accuracy: 0.7258
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8937 - accuracy: 0.6837 - val_loss: 0.8469 - val_accuracy: 0.7063
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8862 - accuracy: 0.6877 - val_loss: 0.8326 - val_accuracy: 0.7127
1563/1563 [==============================] - 18s 11ms/step - loss: 0.8837 - accuracy: 0.6879 - val_loss: 0.8527 - val_accuracy: 0.7024
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8741 - accuracy: 0.6914 - val_loss: 0.9302 - val_accuracy: 0.6772
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8767 - accuracy: 0.6918 - val_loss: 0.7803 - val_accuracy: 0.7256
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8714 - accuracy: 0.6908 - val_loss: 0.7822 - val_accuracy: 0.7246
1563/1563 [==============================] - 18s 11ms/step - loss: 0.8679 - accuracy: 0.6923 - val_loss: 0.8040 - val_accuracy: 0.7215
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8696 - accuracy: 0.6927 - val_loss: 0.8880 - val_accuracy: 0.6940
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8613 - accuracy: 0.6978 - val_loss: 0.8104 - val_accuracy: 0.7175
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8673 - accuracy: 0.6940 - val_loss: 0.8103 - val_accuracy: 0.7181
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8606 - accuracy: 0.6956 - val_loss: 0.8814 - val_accuracy: 0.6989
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8602 - accuracy: 0.6943 - val_loss: 0.8668 - val_accuracy: 0.7022
1563/1563 [==============================] - 20s 13ms/step - loss: 0.8594 - accuracy: 0.6982 - val_loss: 0.7887 - val_accuracy: 0.7267
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8517 - accuracy: 0.6988 - val_loss: 0.7704 - val_accuracy: 0.7295
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8492 - accuracy: 0.6998 - val_loss: 0.8546 - val_accuracy: 0.7040
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8415 - accuracy: 0.7006 - val_loss: 0.8919 - val_accuracy: 0.6920
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8431 - accuracy: 0.7009 - val_loss: 0.9454 - val_accuracy: 0.6762
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8490 - accuracy: 0.6998 - val_loss: 0.8300 - val_accuracy: 0.7122
1563/1563 [==============================] - 19s 12ms/step - loss: 0.8434 - accuracy: 0.7034 - val_loss: 0.9084 - val_accuracy: 0.6917
1563/1563 [==============================] - 19s 12ms/step - loss: 0.8467 - accuracy: 0.7006 - val_loss: 0.8288 - val_accuracy: 0.7128
1563/1563 [==============================] - 19s 12ms/step - loss: 0.8419 - accuracy: 0.7029 - val_loss: 0.7709 - val_accuracy: 0.7278
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8344 - accuracy: 0.7057 - val_loss: 0.7790 - val_accuracy: 0.7299
1563/1563 [==============================] - 19s 12ms/step - loss: 0.8314 - accuracy: 0.7063 - val_loss: 0.7765 - val_accuracy: 0.7296
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8322 - accuracy: 0.7085 - val_loss: 0.7988 - val_accuracy: 0.7221
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8220 - accuracy: 0.7117 - val_loss: 0.8512 - val_accuracy: 0.7039
1563/1563 [==============================] - 18s 12ms/step - loss: 0.8307 - accuracy: 0.7077 - val_loss: 0.7842 - val_accuracy: 0.7275
1563/1563 [==============================] - 19s 12ms/step - loss: 0.8229 - accuracy: 0.7106 - val_loss: 0.8556 - val_accuracy: 0.7035
1563/1563 [==============================] - 21s 13ms/step - loss: 0.8216 - accuracy: 0.7102 - val_loss: 0.8138 - val_accuracy: 0.7169
